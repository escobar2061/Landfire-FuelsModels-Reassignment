{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f7e7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ POLARS: positional CFL / Hazard pipeline ------------------\n",
    "import os\n",
    "from typing import Dict, Iterable, Optional, Tuple, List\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# Optional (only for raster step)\n",
    "try:\n",
    "    import rasterio\n",
    "    from rasterio.transform import Affine\n",
    "except Exception:\n",
    "    rasterio, Affine = None, None\n",
    "\n",
    "# Fixed midpoints (feet) for the 6 flame-length bins\n",
    "FL_MIDPOINTS_FT = (1.0, 3.0, 5.0, 7.0, 10.0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IFTDSS Integrated Hazard lookup (rows=CFL bins, cols=BP % of max bins) ---\n",
    "# CFL bins (row index):\n",
    "# 0: 0–2 ft, 1: 2–4 ft, 2: 4–6 ft, 3: 6–8 ft, 4: 8–12 ft, 5: >12 ft\n",
    "# BP bins (col index):\n",
    "# 0: 0–20%, 1: 20–40%, 2: 40–60%, 3: 60–80%, 4: 80–100%\n",
    "# Values are IH classes: 1=Lowest ... 5=Highest\n",
    "IH_LOOKUP = np.array([\n",
    "    [1, 1, 1, 1, 2],  # 0–2 ft\n",
    "    [1, 1, 2, 2, 3],  # 2–4\n",
    "    [1, 2, 3, 3, 4],  # 4–6\n",
    "    [2, 3, 3, 4, 4],  # 6–8\n",
    "    [3, 3, 4, 4, 5],  # 8–12\n",
    "    [4, 4, 4, 5, 5],  # >12\n",
    "], dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff8f33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- helpers ---------------------------------------------------------------\n",
    "\n",
    "def _header_length(csv_path: str) -> int:\n",
    "    tmp = pl.read_csv(csv_path, n_rows=0, has_header=True, ignore_errors=True)\n",
    "    return len(tmp.columns)\n",
    "\n",
    "def _positional_names(n_cols: int) -> List[str]:\n",
    "    base = [\"XPos\",\"YPos\",\"PBurn\",\"FIL1\",\"FIL2\",\"FIL3\",\"FIL4\",\"FIL5\",\"FIL6\"]\n",
    "    if n_cols <= len(base):\n",
    "        return base[:n_cols]\n",
    "    return base + [f\"COL{i}\" for i in range(10, 10 + (n_cols - len(base)))]\n",
    "\n",
    "def _clean_num(colname: str) -> pl.Expr:\n",
    "    # strip NBSP/BOM/newlines/tabs/spaces and any non [0-9 e/E + - .]\n",
    "    return (\n",
    "        pl.col(colname)\n",
    "        .cast(pl.Utf8, strict=False)\n",
    "        .str.replace_all(r\"[\\u00A0\\uFEFF]\", \"\")       # NBSP/BOM\n",
    "        .str.replace_all(r\"[^\\dEe+\\-\\.]\", \"\")         # keep digits, e/E, sign, dot\n",
    "        .str.strip_chars()\n",
    "        .cast(pl.Float64, strict=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95043694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- core processing -------------------------------------------------------\n",
    "\n",
    "def process_csv_polars_positional(csv_path: str,\n",
    "                                  midpoints_ft: Iterable[float] = FL_MIDPOINTS_FT\n",
    "                                  ) -> pl.DataFrame:\n",
    "    n_cols = _header_length(csv_path)\n",
    "    new_cols = _positional_names(n_cols)\n",
    "\n",
    "    # Force canonical names by position; explicit comma separator & standard quoting\n",
    "    lf = pl.scan_csv(\n",
    "        csv_path,\n",
    "        has_header=True,\n",
    "        new_columns=new_cols,   # positional override\n",
    "        separator=\",\",\n",
    "        quote_char='\"',\n",
    "        ignore_errors=True,\n",
    "    )\n",
    "\n",
    "    # Clean/cast just the needed numeric columns (keep all others intact)\n",
    "    need_num = [c for c in (\"XPos\",\"YPos\",\"PBurn\",\"FIL1\",\"FIL2\",\"FIL3\",\"FIL4\",\"FIL5\",\"FIL6\") if c in new_cols]\n",
    "    lf = lf.with_columns([_clean_num(c).alias(c) for c in need_num])\n",
    "\n",
    "    # Build CFL expression once, and build hazard from the SAME expression (no alias lookup)\n",
    "    fil_cols = [c for c in (\"FIL1\",\"FIL2\",\"FIL3\",\"FIL4\",\"FIL5\",\"FIL6\") if c in new_cols]\n",
    "    weights  = list(midpoints_ft)[:len(fil_cols)]\n",
    "    cfl_expr = pl.sum_horizontal([pl.col(c) * w for c, w in zip(fil_cols, weights)]) if fil_cols else pl.lit(None)\n",
    "    hazard_expr = (pl.sum_horizontal([pl.col(c) * w for c, w in zip(fil_cols, weights)]) * pl.col(\"PBurn\")) if fil_cols else pl.lit(None)\n",
    "\n",
    "    # First collect CFL_ft and continuous hazard\n",
    "    out = (\n",
    "        lf.with_columns([\n",
    "            cfl_expr.alias(\"CFL_ft\"),\n",
    "            hazard_expr.alias(\"hazard\"),\n",
    "        ])\n",
    "        .collect(engine=\"streaming\")\n",
    "    )\n",
    "\n",
    "    # --- IFTDSS classing ---\n",
    "\n",
    "    # 1) BP percent-of-max within this dataset (i.e., within your clipped fireshed box)\n",
    "    bp_max = float(out.select(pl.max(\"PBurn\")).item()) if out.height else 0.0\n",
    "    if bp_max <= 0:\n",
    "        # No burning: set BP % to 0 so everything falls in the lowest BP bin\n",
    "        out = out.with_columns(pl.lit(0.0).alias(\"BP_pct\"))\n",
    "    else:\n",
    "        out = out.with_columns((pl.col(\"PBurn\") / bp_max).alias(\"BP_pct\"))\n",
    "\n",
    "    # 2) BP bin index (0..4): [0–0.2), [0.2–0.4), [0.4–0.6), [0.6–0.8), [0.8–1.0]\n",
    "    bp_idx = (\n",
    "        pl.when(pl.col(\"BP_pct\") < 0.20).then(0)\n",
    "        .when(pl.col(\"BP_pct\") < 0.40).then(1)\n",
    "        .when(pl.col(\"BP_pct\") < 0.60).then(2)\n",
    "        .when(pl.col(\"BP_pct\") < 0.80).then(3)\n",
    "        .otherwise(4)\n",
    "        .cast(pl.UInt8)\n",
    "        .alias(\"BP_bin\")\n",
    "    )\n",
    "\n",
    "    # 3) CFL bin index (0..5): 0–2, 2–4, 4–6, 6–8, 8–12, >12\n",
    "    cfl_idx = (\n",
    "        pl.when(pl.col(\"CFL_ft\") < 2).then(0)\n",
    "        .when(pl.col(\"CFL_ft\") < 4).then(1)\n",
    "        .when(pl.col(\"CFL_ft\") < 6).then(2)\n",
    "        .when(pl.col(\"CFL_ft\") < 8).then(3)\n",
    "        .when(pl.col(\"CFL_ft\") < 12).then(4)\n",
    "        .otherwise(5)\n",
    "        .cast(pl.UInt8)\n",
    "        .alias(\"CFL_bin\")\n",
    "    )\n",
    "\n",
    "    out = out.with_columns([bp_idx, cfl_idx])\n",
    "\n",
    "    # 4) Matrix lookup to get IH class (1..5). Set PBurn==0 -> IH=0 (\"burnable but did not burn\")\n",
    "    # NOTE: If you carry a non-burnable mask, set those to -1 after this step.\n",
    "    bp_bin_np  = out[\"BP_bin\"].to_numpy()\n",
    "    cfl_bin_np = out[\"CFL_bin\"].to_numpy()\n",
    "    ih_np = IH_LOOKUP[cfl_bin_np, bp_bin_np].astype(np.int16)\n",
    "\n",
    "    # PBurn==0 -> 0 (burnable but did not burn)\n",
    "    pburn_np = out[\"PBurn\"].to_numpy()\n",
    "    ih_np[pburn_np == 0] = 0\n",
    "\n",
    "    out = out.with_columns(pl.Series(\"IH_class\", ih_np))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863b3dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_folder_polars_positional(\n",
    "    root_dir: str,\n",
    "    pattern_filename: str = \"FLP_English.csv\",\n",
    "    save_parquet: bool = False,\n",
    "    parquet_out_dir: Optional[str] = None,\n",
    ") -> Dict[str, pl.DataFrame]:\n",
    "    results: Dict[str, pl.DataFrame] = {}\n",
    "    for current_dir, _, files in os.walk(root_dir):\n",
    "        for f in files:\n",
    "            if f == pattern_filename:\n",
    "                csv_path = os.path.join(current_dir, f)\n",
    "                print(f\"[RUN] Processing folder: {current_dir}\")\n",
    "                try:\n",
    "                    df_pl = process_csv_polars_positional(csv_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] Skipping {csv_path}: {e}\")\n",
    "                    continue\n",
    "                results[csv_path] = df_pl\n",
    "                if save_parquet:\n",
    "                    if parquet_out_dir is None:\n",
    "                        parquet_out_dir = os.path.join(root_dir, \"_CFL_parquet\")\n",
    "                    os.makedirs(parquet_out_dir, exist_ok=True)\n",
    "                    rel = os.path.relpath(current_dir, root_dir).replace(os.sep, \"_\")\n",
    "                    out_path = os.path.join(parquet_out_dir, f\"CFL_hazard_{rel or 'root'}.parquet\")\n",
    "                    df_pl.write_parquet(out_path)\n",
    "                    print(f\"[OK] Wrote {out_path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6cdc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- rasterization ------------------------------------------\n",
    "\n",
    "def rasterize_from_polars(\n",
    "    df_pl: pl.DataFrame,\n",
    "    out_path: str,\n",
    "    crs_epsg: Optional[int] = None,\n",
    "    x_col: str = \"XPos\",\n",
    "    y_col: str = \"YPos\",\n",
    "    value_col: str = \"CFL_ft\",   # default: rasterize hazard, CFL_ft\n",
    "    nodata: float = np.nan,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Convert a Polars result (XPos, YPos, and value_col) to a single-band GeoTIFF.\n",
    "    \"\"\"\n",
    "    if rasterio is None or Affine is None:\n",
    "        raise RuntimeError(\"Install 'rasterio' to write rasters.\")\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    def _infer_grid_params(df_xy: pd.DataFrame, x: str, y: str) -> Tuple[np.ndarray, np.ndarray, float, float]:\n",
    "        xs = np.sort(df_xy[x].unique())\n",
    "        ys = np.sort(df_xy[y].unique())\n",
    "        if len(xs) < 2 or len(ys) < 2:\n",
    "            raise ValueError(\"Not enough unique X/Y positions to form a grid.\")\n",
    "        dxs = np.diff(xs); dys = np.diff(ys)\n",
    "        # modal step (robust to occasional gaps)\n",
    "        def modal_step(arr: np.ndarray) -> float:\n",
    "            vals, counts = np.unique(np.round(arr, 6), return_counts=True)\n",
    "            return float(vals[np.argmax(counts)])\n",
    "        return xs, ys, modal_step(dxs), modal_step(dys)\n",
    "\n",
    "    df_pd = df_pl.to_pandas()\n",
    "\n",
    "    xs, ys, dx, dy = _infer_grid_params(df_pd, x_col, y_col)\n",
    "    x_to_idx = {x: i for i, x in enumerate(xs)}\n",
    "    y_to_idx = {y: i for i, y in enumerate(ys)}\n",
    "\n",
    "    ncols, nrows = len(xs), len(ys)\n",
    "    arr = np.full((nrows, ncols), np.nan, dtype=np.float32)\n",
    "\n",
    "    for _, r in df_pd.iterrows():\n",
    "        ci = x_to_idx[r[x_col]]\n",
    "        ri = (nrows - 1 - y_to_idx[r[y_col]])  # top row = max Y\n",
    "        arr[ri, ci] = float(r[value_col])\n",
    "\n",
    "    min_x, max_y = xs.min(), ys.max()\n",
    "    transform = Affine.translation(min_x - dx/2.0, max_y + dy/2.0) * Affine.scale(dx, -dy)\n",
    "\n",
    "    profile = dict(\n",
    "        driver=\"GTiff\", height=nrows, width=ncols, count=1, dtype=\"float32\",\n",
    "        transform=transform, compress=\"lzw\", nodata=nodata, tiled=True, interleave=\"band\",\n",
    "        crs=(f\"EPSG:{crs_epsg}\" if crs_epsg is not None else None),\n",
    "    )\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(arr, 1)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ffed769",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\WFM Outputs\\run_97th_percentiles\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a986409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] Processing folder: C:\\Users\\bsf31\\Documents\\data\\NL060\\WFM Outputs\\run_97th_percentiles\\Central_Coast\n",
      "[RUN] Processing folder: C:\\Users\\bsf31\\Documents\\data\\NL060\\WFM Outputs\\run_97th_percentiles\\Cuyama\n",
      "[RUN] Processing folder: C:\\Users\\bsf31\\Documents\\data\\NL060\\WFM Outputs\\run_97th_percentiles\\Santa_Ynez\n",
      "[RUN] Processing folder: C:\\Users\\bsf31\\Documents\\data\\NL060\\WFM Outputs\\run_97th_percentiles\\South_Coast_E\n",
      "[RUN] Processing folder: C:\\Users\\bsf31\\Documents\\data\\NL060\\WFM Outputs\\run_97th_percentiles\\South_Coast_W\n"
     ]
    }
   ],
   "source": [
    "# 1) Process all subfolders (prints progress), keep results in memory\n",
    "results = batch_process_folder_polars_positional(root_dir, save_parquet=False)  # Parquet optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af39855a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3_695_856, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>XPos</th><th>YPos</th><th>PBurn</th><th>FIL1</th><th>FIL2</th><th>FIL3</th><th>FIL4</th><th>FIL5</th><th>FIL6</th><th>CFL_ft</th><th>hazard</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>164481.34375</td><td>3.882655e6</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>164511.34375</td><td>3.882655e6</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>164541.34375</td><td>3.882655e6</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>164571.34375</td><td>3.882655e6</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>164601.34375</td><td>3.882655e6</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>217611.34375</td><td>3.820255e6</td><td>0.007917</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>217641.34375</td><td>3.820255e6</td><td>0.007917</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>217671.34375</td><td>3.820255e6</td><td>0.007917</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>217701.34375</td><td>3.820255e6</td><td>0.007917</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>217731.34375</td><td>3.820255e6</td><td>0.007917</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3_695_856, 11)\n",
       "┌──────────────┬────────────┬──────────┬──────┬───┬──────┬──────┬────────┬────────┐\n",
       "│ XPos         ┆ YPos       ┆ PBurn    ┆ FIL1 ┆ … ┆ FIL5 ┆ FIL6 ┆ CFL_ft ┆ hazard │\n",
       "│ ---          ┆ ---        ┆ ---      ┆ ---  ┆   ┆ ---  ┆ ---  ┆ ---    ┆ ---    │\n",
       "│ f64          ┆ f64        ┆ f64      ┆ f64  ┆   ┆ f64  ┆ f64  ┆ f64    ┆ f64    │\n",
       "╞══════════════╪════════════╪══════════╪══════╪═══╪══════╪══════╪════════╪════════╡\n",
       "│ 164481.34375 ┆ 3.882655e6 ┆ 0.0      ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 164511.34375 ┆ 3.882655e6 ┆ 0.0      ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 164541.34375 ┆ 3.882655e6 ┆ 0.0      ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 164571.34375 ┆ 3.882655e6 ┆ 0.0      ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 164601.34375 ┆ 3.882655e6 ┆ 0.0      ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ …            ┆ …          ┆ …        ┆ …    ┆ … ┆ …    ┆ …    ┆ …      ┆ …      │\n",
       "│ 217611.34375 ┆ 3.820255e6 ┆ 0.007917 ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 217641.34375 ┆ 3.820255e6 ┆ 0.007917 ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 217671.34375 ┆ 3.820255e6 ┆ 0.007917 ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 217701.34375 ┆ 3.820255e6 ┆ 0.007917 ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "│ 217731.34375 ┆ 3.820255e6 ┆ 0.007917 ┆ 0.0  ┆ … ┆ 0.0  ┆ 0.0  ┆ 0.0    ┆ 0.0    │\n",
       "└──────────────┴────────────┴──────────┴──────┴───┴──────┴──────┴────────┴────────┘"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one result (XPos, YPos, PBurn, CFL_ft, hazard)\n",
    "any_df = next(iter(results.values()))\n",
    "any_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aec645",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2) rasterize HAZARD per folder\n",
    "for csv_path, df_pl in results.items():\n",
    "    # Name output by folder\n",
    "    rel = os.path.relpath(os.path.dirname(csv_path), root_dir).replace(os.sep, \"_\")\n",
    "    out_tif = os.path.join(root_dir, \"_CFL_rasters\", f\"hazard_{rel or 'root'}.tif\")\n",
    "    rasterize_from_polars(df_pl, out_tif, crs_epsg=26911)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb777892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) rasterize CFL_ft per folder\n",
    "for csv_path, df_pl in results.items():\n",
    "    # Name output by folder\n",
    "    rel = os.path.relpath(os.path.dirname(csv_path), root_dir).replace(os.sep, \"_\")\n",
    "    out_tif = os.path.join(root_dir, \"_CFL_rasters\", f\"CFL_ft_{rel or 'root'}.tif\")\n",
    "    rasterize_from_polars(df_pl, out_tif, crs_epsg=26911)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
