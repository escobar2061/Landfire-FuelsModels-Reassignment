{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "036e0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces: 2583  Perims: 487\n",
      "Perimeters with parsed ALARM_DATE: 329 / 487\n",
      "Intersections total (raw): 8857  polygonal kept: 5452\n",
      "âœ… Wrote tagged faces to layer: california_fir_featuretopoly_tagged\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "from shapely.geometry import Polygon, MultiPolygon, GeometryCollection\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "# -----------------------\n",
    "# Params\n",
    "# -----------------------\n",
    "project_db   = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\CA_FIRES.gpkg\"\n",
    "faces_layer  = \"california_fir_featuretopoly\"   # non-overlapping faces (Feature to Polygon)\n",
    "perims_layer = \"california_fire_perimet_clip\"   # original clipped perimeters\n",
    "n_years      = 20                                # \"recent\" window\n",
    "\n",
    "# Columns\n",
    "name_col = \"FIRE_NAME\"\n",
    "date_col = \"ALARM_DATE\"  # e.g., \"1/7/2025 08:00:00 (UTC)\"\n",
    "year_col = \"YEAR_\"       # optional fallback if ALARM_DATE is missing\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def parse_alarm_datetime_utc(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parse ALARM_DATE robustly and return tz-aware UTC timestamps (NaT on fail).\"\"\"\n",
    "    # strip any trailing parenthetical timezone like (UTC), (UTC-08:00), (PDT), etc.\n",
    "    s = series.astype(str).str.replace(r\"\\s*\\([^)]*\\)\\s*$\", \"\", regex=True).str.strip()\n",
    "    # allow both 12/31/2024 23:59:59 and ISO-like strings; force UTC\n",
    "    return pd.to_datetime(s, errors=\"coerce\", utc=True)\n",
    "\n",
    "def polygonal_part_or_none(geom):\n",
    "    \"\"\"Return polygonal part of geometry; None if no polygonal area exists.\"\"\"\n",
    "    if geom is None or geom.is_empty:\n",
    "        return None\n",
    "    gt = geom.geom_type\n",
    "    if gt in (\"Polygon\", \"MultiPolygon\"):\n",
    "        return geom\n",
    "    if gt == \"GeometryCollection\":\n",
    "        polys = [g for g in geom.geoms if g.geom_type in (\"Polygon\", \"MultiPolygon\")]\n",
    "        if not polys:\n",
    "            return None\n",
    "        # If there are multiple polygon bits, return their union (still polygonal)\n",
    "        try:\n",
    "            return unary_union(polys)\n",
    "        except Exception:\n",
    "            # Fallback: return MultiPolygon of the polygon parts\n",
    "            flat = []\n",
    "            for g in polys:\n",
    "                if g.geom_type == \"Polygon\":\n",
    "                    flat.append(g)\n",
    "                else:\n",
    "                    flat.extend(list(g.geoms))\n",
    "            return MultiPolygon(flat) if flat else None\n",
    "    # LineString/Point etc. -> no area\n",
    "    return None\n",
    "\n",
    "# -----------------------\n",
    "# Load\n",
    "# -----------------------\n",
    "faces  = gpd.read_file(project_db, layer=faces_layer)\n",
    "perims = gpd.read_file(project_db, layer=perims_layer)\n",
    "\n",
    "# CRS match\n",
    "if faces.crs != perims.crs:\n",
    "    perims = perims.to_crs(faces.crs)\n",
    "\n",
    "# Quick geom repair on perimeters (faces from FeatureToPoly are usually fine)\n",
    "# (buffer(0) is safe; if using geographic CRS it's still okay with distance=0)\n",
    "perims[\"geometry\"] = perims.geometry.buffer(0)\n",
    "\n",
    "# Ensure faces have a stable id\n",
    "if \"piece_id\" not in faces.columns:\n",
    "    faces = faces.copy()\n",
    "    faces[\"piece_id\"] = np.arange(len(faces), dtype=int)\n",
    "\n",
    "# Parse ALARM_DATE robustly\n",
    "has_date_col = date_col in perims.columns\n",
    "if has_date_col:\n",
    "    perims[\"ALARM_DATE_UTC\"] = parse_alarm_datetime_utc(perims[date_col])\n",
    "else:\n",
    "    perims[\"ALARM_DATE_UTC\"] = pd.NaT\n",
    "\n",
    "# YEAR_ fallback (if present)\n",
    "has_year_col = year_col in perims.columns\n",
    "if has_year_col:\n",
    "    perims[year_col] = pd.to_numeric(perims[year_col], errors=\"coerce\")\n",
    "\n",
    "# -----------------------\n",
    "# Intersection with polygonal cleanup\n",
    "# -----------------------\n",
    "faces_slim  = faces[[\"piece_id\", \"geometry\"]].copy()\n",
    "perims_slim = perims[[name_col, \"ALARM_DATE_UTC\", year_col] if has_year_col else [name_col, \"ALARM_DATE_UTC\", \"geometry\"]].copy()\n",
    "if \"geometry\" not in perims_slim.columns:\n",
    "    perims_slim = perims[[name_col, \"ALARM_DATE_UTC\", year_col, \"geometry\"]]\n",
    "\n",
    "# Use keep_geom_type=False to avoid losing GeometryCollections;\n",
    "# then convert intersections to polygonal parts only.\n",
    "inter_raw = gpd.overlay(faces_slim, perims_slim, how=\"intersection\", keep_geom_type=False)\n",
    "\n",
    "# Keep only polygonal area from any GeometryCollections\n",
    "inter_raw[\"geometry\"] = inter_raw.geometry.apply(polygonal_part_or_none)\n",
    "inter = inter_raw[~inter_raw.geometry.isna() & ~inter_raw.geometry.is_empty].copy()\n",
    "\n",
    "# ---- Diagnostics\n",
    "print(f\"Faces: {len(faces)}  Perims: {len(perims)}\")\n",
    "n_dates = perims[\"ALARM_DATE_UTC\"].notna().sum()\n",
    "print(f\"Perimeters with parsed ALARM_DATE: {n_dates} / {len(perims)}\")\n",
    "print(f\"Intersections total (raw): {len(inter_raw)}  polygonal kept: {len(inter)}\")\n",
    "\n",
    "if inter.empty:\n",
    "    out = faces.copy()\n",
    "    out[\"LATEST_YEAR\"]  = pd.Series(dtype=\"Int64\")\n",
    "    out[\"LATEST_FIRE\"]  = pd.Series(dtype=\"object\")\n",
    "    out[\"LATEST_ALARM\"] = pd.Series(dtype=\"object\")   # ISO date string (or None)\n",
    "    out[\"BURN_COUNT\"]   = 0\n",
    "    out[\"HAS_OVERLAP\"]  = 0\n",
    "    cutoff_ts = pd.Timestamp.now(tz=\"UTC\") - pd.DateOffset(years=n_years)\n",
    "    out[f\"RECENT_{n_years}Y\"] = 0\n",
    "else:\n",
    "    # Build an event key with tolerance:\n",
    "    # 1) Prefer calendar date of ALARM_DATE\n",
    "    inter[\"ALARM_DATE_DATE\"] = inter[\"ALARM_DATE_UTC\"].dt.date\n",
    "\n",
    "    # 2) If ALARM_DATE is NaT but YEAR_ exists, use YEAR_ as fallback\n",
    "    # (so big events with missing timestamps don't vanish)\n",
    "    if has_year_col:\n",
    "        inter[\"EVENT_KEY\"] = inter[\"ALARM_DATE_DATE\"].astype(\"object\")\n",
    "        mask_nat = inter[\"EVENT_KEY\"].isna()\n",
    "        inter.loc[mask_nat, \"EVENT_KEY\"] = inter.loc[mask_nat, year_col].astype(\"Int64\")\n",
    "\n",
    "        # For \"latest\" selection: construct a sortable proxy timestamp\n",
    "        # Prefer ALARM_DATE_UTC; else use Jan 1 of YEAR_ (UTC)\n",
    "        inter[\"ALARM_OR_YEAR_TS\"] = inter[\"ALARM_DATE_UTC\"]\n",
    "        mask_ts_nat = inter[\"ALARM_OR_YEAR_TS\"].isna() & inter[year_col].notna()\n",
    "        inter.loc[mask_ts_nat, \"ALARM_OR_YEAR_TS\"] = pd.to_datetime(\n",
    "            inter.loc[mask_ts_nat, year_col].astype(int).astype(str) + \"-01-01\",\n",
    "            utc=True, errors=\"coerce\"\n",
    "        )\n",
    "    else:\n",
    "        inter[\"EVENT_KEY\"] = inter[\"ALARM_DATE_DATE\"]\n",
    "        inter[\"ALARM_OR_YEAR_TS\"] = inter[\"ALARM_DATE_UTC\"]\n",
    "\n",
    "    # Count unique events per face: distinct (FIRE_NAME, EVENT_KEY)\n",
    "    unique_events = (\n",
    "        inter.dropna(subset=[\"EVENT_KEY\"])\n",
    "             .drop_duplicates(subset=[\"piece_id\", name_col, \"EVENT_KEY\"])\n",
    "    )\n",
    "    counts = unique_events.groupby(\"piece_id\").size().rename(\"BURN_COUNT\")\n",
    "\n",
    "    # Latest event per face by ALARM_OR_YEAR_TS (UTC)\n",
    "    top = (\n",
    "        inter.sort_values([\"piece_id\", \"ALARM_OR_YEAR_TS\"], ascending=[True, False])\n",
    "             .drop_duplicates(subset=\"piece_id\")\n",
    "             .loc[:, [\"piece_id\", name_col, \"ALARM_DATE_UTC\", \"ALARM_OR_YEAR_TS\"]]\n",
    "             .rename(columns={name_col: \"LATEST_FIRE\"})\n",
    "    )\n",
    "    top[\"LATEST_YEAR\"]  = top[\"ALARM_OR_YEAR_TS\"].dt.year.astype(\"Int64\")\n",
    "    top[\"LATEST_ALARM\"] = top[\"ALARM_DATE_UTC\"].dt.strftime(\"%Y-%m-%d\")  # ISO if available\n",
    "\n",
    "    # Merge onto faces\n",
    "    out = faces.merge(top[[\"piece_id\", \"LATEST_FIRE\", \"LATEST_YEAR\", \"LATEST_ALARM\"]],\n",
    "                      on=\"piece_id\", how=\"left\") \\\n",
    "               .merge(counts, on=\"piece_id\", how=\"left\")\n",
    "\n",
    "    # Flags\n",
    "    out[\"BURN_COUNT\"]  = out[\"BURN_COUNT\"].fillna(0).astype(\"int32\")\n",
    "    out[\"HAS_OVERLAP\"] = (out[\"BURN_COUNT\"] > 1).astype(\"uint8\")\n",
    "\n",
    "    # Recent flag using ALARM_OR_YEAR_TS (so YEAR_ fallback still participates)\n",
    "    cutoff_ts = pd.Timestamp.now(tz=\"UTC\") - pd.DateOffset(years=n_years)\n",
    "    latest_ts = top.set_index(\"piece_id\")[\"ALARM_OR_YEAR_TS\"]\n",
    "    out = out.join(latest_ts.rename(\"__LATEST_TS__\"), on=\"piece_id\")\n",
    "    out[f\"RECENT_{n_years}Y\"] = out[\"__LATEST_TS__\"].ge(cutoff_ts).fillna(False).astype(\"uint8\")\n",
    "    out = out.drop(columns=\"__LATEST_TS__\")\n",
    "\n",
    "# -----------------------\n",
    "# Write a clean schema\n",
    "# -----------------------\n",
    "keep_cols   = [\n",
    "    \"piece_id\", \"geometry\",\n",
    "    \"BURN_COUNT\", \"HAS_OVERLAP\",\n",
    "    \"LATEST_YEAR\", \"LATEST_FIRE\", \"LATEST_ALARM\",\n",
    "    f\"RECENT_{n_years}Y\"\n",
    "]\n",
    "out_to_write = out[keep_cols].copy()\n",
    "\n",
    "out_layer = f\"{faces_layer}_tagged\"\n",
    "\n",
    "out_to_write.to_file(project_db, layer=out_layer, driver=\"GPKG\")\n",
    "print(f\"âœ… Wrote tagged faces to layer: {out_layer}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
