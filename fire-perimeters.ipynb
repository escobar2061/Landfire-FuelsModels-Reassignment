{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab23e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from rasterstats import zonal_stats\n",
    "from dbfread import DBF\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f039f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# Params\n",
    "# -----------------------\n",
    "project_db   = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\NL060.gpkg\"\n",
    "faces_layer  = \"California_Fir_FeatureToPoly\"   # non-overlapping faces (Feature to Polygon)\n",
    "perims_layer = \"California_Fire_Perimet_Clip\"   # original clipped perimeters\n",
    "n_years      = 20                                # \"recent\" window\n",
    "\n",
    "# Your known columns on the perimeters layer\n",
    "year_col = \"YEAR_\"\n",
    "name_col = \"FIRE_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec568c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Load\n",
    "# -----------------------\n",
    "faces  = gpd.read_file(project_db, layer=faces_layer)\n",
    "perims = gpd.read_file(project_db, layer=perims_layer)\n",
    "\n",
    "# CRS match\n",
    "if faces.crs != perims.crs:\n",
    "    perims = perims.to_crs(faces.crs)\n",
    "\n",
    "# Coerce year to numeric (safe even if already numeric)\n",
    "perims[year_col] = pd.to_numeric(perims[year_col], errors=\"coerce\")\n",
    "\n",
    "# Quick geom repair on perimeters (faces from FeatureToPoly are usually fine)\n",
    "perims[\"geometry\"] = perims.geometry.buffer(0)\n",
    "\n",
    "# Ensure faces have a stable id\n",
    "if \"piece_id\" not in faces.columns:\n",
    "    faces = faces.copy()\n",
    "    faces[\"piece_id\"] = np.arange(len(faces), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# Area-based intersection (no edge-only matches), NO sliver filtering\n",
    "# -----------------------\n",
    "faces_slim  = faces[[\"piece_id\", \"geometry\"]].copy()\n",
    "perims_slim = perims[[year_col, name_col, \"geometry\"]].copy()\n",
    "\n",
    "inter = gpd.overlay(faces_slim, perims_slim, how=\"intersection\", keep_geom_type=True)\n",
    "\n",
    "if inter.empty:\n",
    "    out = faces.copy()\n",
    "    out[\"LATEST_YEAR\"] = pd.Series(dtype=\"Int64\")\n",
    "    out[\"LATEST_FIRE\"] = pd.Series(dtype=\"object\")\n",
    "    out[\"BURN_COUNT\"]  = 0\n",
    "    out[\"HAS_OVERLAP\"] = 0\n",
    "    cutoff = datetime.now().year - n_years\n",
    "    out[f\"RECENT_{n_years}Y\"] = 0\n",
    "else:\n",
    "    # Count how many perimeters truly overlap each face\n",
    "    counts = inter.groupby(\"piece_id\")[year_col].size().rename(\"BURN_COUNT\")\n",
    "\n",
    "    # Pick the perimeter row with MAX year per face\n",
    "    top = (\n",
    "        inter.sort_values([\"piece_id\", year_col], ascending=[True, False])\n",
    "            .drop_duplicates(subset=\"piece_id\")\n",
    "            .loc[:, [\"piece_id\", year_col, name_col]]\n",
    "            .rename(columns={year_col: \"LATEST_YEAR\", name_col: \"LATEST_FIRE\"})\n",
    "    )\n",
    "\n",
    "    # Merge onto faces\n",
    "    out = faces.merge(top, on=\"piece_id\", how=\"left\").merge(counts, on=\"piece_id\", how=\"left\")\n",
    "\n",
    "    # Flags (store as 0/1 for GPKG friendliness)\n",
    "    out[\"BURN_COUNT\"]  = out[\"BURN_COUNT\"].fillna(0).astype(\"int32\")\n",
    "    out[\"HAS_OVERLAP\"] = (out[\"BURN_COUNT\"] > 1).astype(\"uint8\")\n",
    "\n",
    "    cutoff = datetime.now().year - n_years   # with 2025 and 20 yrs => 2005\n",
    "    out[f\"RECENT_{n_years}Y\"] = out[\"LATEST_YEAR\"].ge(cutoff).fillna(False).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f5f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------\n",
    "# Write a clean schema\n",
    "# -----------------------\n",
    "keep_cols   = [\"piece_id\", \"geometry\", \"BURN_COUNT\", \"HAS_OVERLAP\", \"LATEST_YEAR\", \"LATEST_FIRE\", f\"RECENT_{n_years}Y\"]\n",
    "out_to_write = out[keep_cols].copy()\n",
    "\n",
    "out_layer = f\"{faces_layer}_tagged\"\n",
    "out_to_write.to_file(project_db, layer=out_layer, driver=\"GPKG\")\n",
    "print(f\"✅ Wrote tagged faces to layer: {out_layer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca60038",
   "metadata": {},
   "source": [
    "# Zonal Stats Firesheds/ Scott & Burgan 40 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677beb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Inputs and Load\n",
    "# -----------------------\n",
    "project_db   = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\NL060.gpkg\"\n",
    "sb_firesheds = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\sb_firesheds_v02a_20250821.gpkg\"\n",
    "dbf_path    = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\landfire_meszxc7dfpgmqh\\LF2024_FBFM40_250_CONUS\\LF24_F40_250.dbf\"\n",
    "raster_path  = r\"C:\\Users\\bsf31\\Documents\\data\\NL060\\landfire_meszxc7dfpgmqh\\LF2024_FBFM40_250_CONUS\\LC24_F40_250.tif\"\n",
    "\n",
    "latest_fire_name  = \"latest_fire_name_alisal\"   \n",
    "sb_fireshed = 'alisal_buffer'\n",
    "\n",
    "alisal_fire = gpd.read_file(project_db, layer=latest_fire_name)\n",
    "firesheds = gpd.read_file(project_db, layer=sb_fireshed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfaeafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {\n",
    "    # --- GRASS ---\n",
    "    \"GR1\": (\"Grass\", \"Arid–semiarid (EMC 15%)\", \"Short, patchy, possibly grazed; spread moderate; flame low.\"),\n",
    "    \"GR2\": (\"Grass\", \"Arid–semiarid (EMC 15%)\", \"Moderately coarse, ~1 ft; spread high; flame moderate.\"),\n",
    "    \"GR4\": (\"Grass\", \"Arid–semiarid (EMC 15%)\", \"Moderately coarse, ~2 ft; spread very high; flame high.\"),\n",
    "    \"GR7\": (\"Grass\", \"Arid–semiarid (EMC 15%)\", \"Moderately coarse, ~3 ft; spread very high; flame very high.\"),\n",
    "    \"GR3\": (\"Grass\", \"Subhumid–humid (EMC 30–40%)\", \"Very coarse, ~2 ft; spread high; flame moderate.\"),\n",
    "    \"GR5\": (\"Grass\", \"Subhumid–humid (EMC 30–40%)\", \"Dense, coarse, 1–2 ft; spread very high; flame high.\"),\n",
    "    \"GR6\": (\"Grass\", \"Subhumid–humid (EMC 30–40%)\", \"Dryland grass 1–2 ft; spread very high; flame very high.\"),\n",
    "    \"GR8\": (\"Grass\", \"Subhumid–humid (EMC 30–40%)\", \"Heavy, coarse, 3–5 ft; spread very high; flame very high.\"),\n",
    "    \"GR9\": (\"Grass\", \"Subhumid–humid (EMC 30–40%)\", \"Very heavy, coarse, 5–8 ft; spread extreme; flame extreme.\"),\n",
    "    # --- GRASS-SHRUB ---\n",
    "    \"GS1\": (\"Grass-Shrub\", \"Arid–semiarid (EMC 15%)\", \"Shrubs ~1 ft, low grass; spread moderate; flame low.\"),\n",
    "    \"GS2\": (\"Grass-Shrub\", \"Arid–semiarid (EMC 15%)\", \"Shrubs 1–3 ft, moderate grass; spread high; flame moderate.\"),\n",
    "    \"GS3\": (\"Grass-Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Moderate grass/shrub <2 ft; spread high; flame moderate.\"),\n",
    "    \"GS4\": (\"Grass-Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Heavy grass/shrub >2 ft; spread high; flame very high.\"),\n",
    "    # --- SHRUB ---\n",
    "    \"SH1\": (\"Shrub\", \"Arid–semiarid (EMC 15%)\", \"Low shrub load ~1 ft; spread very low; flame very low.\"),\n",
    "    \"SH2\": (\"Shrub\", \"Arid–semiarid (EMC 15%)\", \"Moderate load ~1 ft; no grass; spread low; flame low.\"),\n",
    "    \"SH5\": (\"Shrub\", \"Arid–semiarid (EMC 15%)\", \"Heavy shrubs 4–6 ft; spread very high; flame very high.\"),\n",
    "    \"SH7\": (\"Shrub\", \"Arid–semiarid (EMC 15%)\", \"Very heavy shrubs 4–6 ft; spread high; flame very high.\"),\n",
    "    \"SH3\": (\"Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Moderate shrubs (maybe pine/herb); 2–3 ft; spread low; flame low.\"),\n",
    "    \"SH4\": (\"Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Low–moderate shrubs/litter (~3 ft); spread high; flame moderate.\"),\n",
    "    \"SH6\": (\"Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Dense shrubs, little/no herb; ~2 ft; spread high; flame high.\"),\n",
    "    \"SH8\": (\"Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Dense shrubs, ~3 ft; spread high; flame high.\"),\n",
    "    \"SH9\": (\"Shrub\", \"Subhumid–humid (EMC 30–40%)\", \"Dense, fine-branched, 4–6 ft; spread high; flame very high.\"),\n",
    "    # --- TIMBER-UNDERSTORY ---\n",
    "    \"TU1\": (\"Timber-Understory\", \"Semiarid–subhumid (EMC 20%)\", \"Low grass/shrub + litter; spread low; flame low.\"),\n",
    "    \"TU2\": (\"Timber-Understory\", \"Humid (EMC 30%)\", \"Moderate litter with shrubs; spread moderate; flame low.\"),\n",
    "    \"TU3\": (\"Timber-Understory\", \"Humid (EMC 30%)\", \"Moderate litter + grass/shrubs; spread high; flame moderate.\"),\n",
    "    \"TU4\": (\"Timber-Understory\", \"Semiarid–subhumid (EMC 20%)\", \"Short conifers w/ grass/moss; spread moderate; flame moderate.\"),\n",
    "    \"TU5\": (\"Timber-Understory\", \"Semiarid–subhumid (EMC 20%)\", \"High conifer litter + shrubs; spread moderate; flame moderate.\"),\n",
    "    # --- TIMBER LITTER ---\n",
    "    \"TL1\": (\"Timber Litter\", \"Recently burned\", \"Light–moderate load, 1–2 in deep; spread very low; flame very low.\"),\n",
    "    \"TL2\": (\"Timber Litter\", \"Broadleaf litter\", \"Low load, compact; spread very low; flame very low.\"),\n",
    "    \"TL3\": (\"Timber Litter\", \"Other conifer litter\", \"Moderate conifer litter; spread very low; flame low.\"),\n",
    "    \"TL4\": (\"Timber Litter\", \"Mixed fine & coarse\", \"Moderate load incl. small logs; spread low; flame low.\"),\n",
    "    \"TL5\": (\"Timber Litter\", \"Conifer litter\", \"High load; light slash/mortality; spread low; flame low.\"),\n",
    "    \"TL6\": (\"Timber Litter\", \"Broadleaf litter\", \"Moderate load, less compact; spread moderate; flame low.\"),\n",
    "    \"TL7\": (\"Timber Litter\", \"Mixed fine & coarse\", \"Heavy load incl. larger logs; spread low; flame low.\"),\n",
    "    \"TL8\": (\"Timber Litter\", \"Long-needle pine\", \"Moderate load/compact; some herb; spread moderate; flame low.\"),\n",
    "    \"TL9\": (\"Timber Litter\", \"Broadleaf / needle drape\", \"Very high load; spread moderate; flame moderate.\"),\n",
    "    # --- SLASH/BLOWDOWN ---\n",
    "    \"SB1\": (\"Slash-Blowdown\", \"Activity fuel\", \"10–20 t/ac; fuels 1–3 in; <1 ft depth; spread moderate; flame low.\"),\n",
    "    \"SB2\": (\"Slash-Blowdown\", \"Activity fuel\", \"7–12 t/ac; even 0–3 in; ~1 ft; spread moderate; flame moderate.\"),\n",
    "    \"SB3\": (\"Slash-Blowdown\", \"Activity fuel\", \"7–12 t/ac; weighted to <0.25 in; >1 ft; spread high; flame high.\"),\n",
    "    # blowdown variants share codes with SB2/SB3/SB4 as behavior descriptors\n",
    "    \"SB4\": (\"Slash-Blowdown\", \"Blowdown (total)\", \"Total blowdown; not compacted; foliage attached; spread very high; flame very high.\"),\n",
    "    # --- NONBURNABLE ---\n",
    "    \"NB1\": (\"Nonburnable\", \"—\", \"Urban/suburban; insufficient wildland fuel.\"),\n",
    "    \"NB2\": (\"Nonburnable\", \"—\", \"Snow/ice.\"),\n",
    "    \"NB3\": (\"Nonburnable\", \"—\", \"Agricultural field maintained nonburnable.\"),\n",
    "    \"NB8\": (\"Nonburnable\", \"—\", \"Open water.\"),\n",
    "    \"NB9\": (\"Nonburnable\", \"—\", \"Bare ground.\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1518ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fbfm40_meta = (\n",
    "    pd.DataFrame.from_dict(meta, orient=\"index\", columns=[\"general_type\", \"climate\", \"summary\"])\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"MODEL\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed6d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only those with the recent fire flag set\n",
    "#recent_faces = tagged[tagged[\"RECENT_20Y\"] == 1].copy()\n",
    "\n",
    "# -----------------------\n",
    "# Dissolve by LATEST_FIRE\n",
    "# -----------------------\n",
    "# One polygon per fire name, but only for flagged ones\n",
    "#groups = recent_faces.dissolve(by=\"LATEST_FIRE\", as_index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Read DBF to DataFrame\n",
    "tbl = DBF(dbf_path, load=True, char_decode_errors='ignore')\n",
    "lut_df = pd.DataFrame(iter(tbl))\n",
    "value_col = 'VALUE'\n",
    "model_col = \"FBFM40\"\n",
    "# Keep just code + label; standardize names\n",
    "lut_df = lut_df[[value_col, model_col]].copy()\n",
    "lut_df.columns = [\"VALUE\", \"FBFM40\"]\n",
    "lut_df = lut_df.rename(columns={\"FBFM40\": \"MODEL\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea678f6",
   "metadata": {},
   "source": [
    "# Zonal Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Run zonal statistics\n",
    "# -----------------------\n",
    "zs = zonal_stats(\n",
    "    firesheds,\n",
    "    raster_path,\n",
    "    categorical=True,   # return pixel counts per EVT code\n",
    "    nodata=-9999)\n",
    "\n",
    "# 3) Build long table from your zs (fid, VALUE, pixels)\n",
    "rows = []\n",
    "for fid, counts in enumerate(zs):\n",
    "    for val, cnt in counts.items():\n",
    "        rows.append({\"fid\": fid, \"VALUE\": int(val), \"pixels\": int(cnt)})\n",
    "df_counts = pd.DataFrame(rows)\n",
    "# 4) Join codes → names\n",
    "df_counts = df_counts.merge(lut_df, on=\"VALUE\", how=\"left\")\n",
    "df_counts = df_counts.merge(fbfm40_meta, on=\"MODEL\", how=\"left\")\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Attach results back to the GeoDataFrame\n",
    "firesheds[\"fbfm40_unique\"] = [list(s.keys()) for s in zs]\n",
    "firesheds[[\"fbfm40_unique\"]]\n",
    "\n",
    "# 5) Attach unique lists back to firesheds\n",
    "uniq_codes = (\n",
    "    df_counts.groupby(\"fid\")[\"VALUE\"]\n",
    "    .apply(lambda s: sorted(set(s.tolist())))\n",
    "    .rename(\"fbfm40_unique_codes\")\n",
    ")\n",
    "uniq_names = (\n",
    "    df_counts.groupby(\"fid\")[\"FBFM40_LABEL\"]\n",
    "    .apply(lambda s: sorted(set([x for x in s.tolist() if pd.notnull(x)])))\n",
    "    .rename(\"fbfm40_unique_names\")\n",
    ")\n",
    "\n",
    "firesheds = firesheds.join(uniq_codes, how=\"left\")\n",
    "firesheds = firesheds.join(uniq_names, how=\"left\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd0e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Save\n",
    "# -----------------------\n",
    "\"\"\" out_layer = f\"{faces_layer}_zonal_byfire_recent\"\n",
    "out.to_file(project_db, layer=out_layer, driver=\"GPKG\")\n",
    "\n",
    "print(\"✅ Zonal stats by fire (RECENT_20Y == 1) complete\")\n",
    "print(out[[\"LATEST_FIRE\", \"count\", \"majority_evt\"]].head()) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236b0c0",
   "metadata": {},
   "source": [
    "# Scott & Burgan 40 metadata Fields: general_type, climate, summary (short description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Run zonal statistics\n",
    "# -----------------------\n",
    "zs_lf = zonal_stats(\n",
    "    alisal_fire,\n",
    "    raster_path,\n",
    "    categorical=True,   # return pixel counts per EVT code\n",
    "    nodata=-9999)\n",
    "\n",
    "# 3) Build long table from  zs_latest_fire (fid, VALUE, pixels)\n",
    "rows = []\n",
    "for fid, counts in enumerate(zs_lf):\n",
    "    for val, cnt in counts.items():\n",
    "        rows.append({\"fid\": fid, \"VALUE\": int(val), \"pixels\": int(cnt)})\n",
    "df_counts_lf = pd.DataFrame(rows)\n",
    "# 4) Join codes → names\n",
    "df_counts_lf = df_counts_lf.merge(lut_df, on=\"VALUE\", how=\"left\")\n",
    "df_counts_lf = df_counts_lf.merge(fbfm40_meta, on=\"MODEL\", how=\"left\")\n",
    "df_counts_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b668e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMILY_ORDERS = {\n",
    "    'GR': ['GR1','GR2','GR3','GR4','GR5','GR6','GR7','GR8','GR9'],\n",
    "    'GS': ['GS1','GS2','GS3','GS4'],\n",
    "    'SH': ['SH1','SH2','SH3','SH4','SH5','SH6','SH7','SH8','SH9'],\n",
    "    'TU': ['TU1','TU2','TU3','TU4','TU5'],\n",
    "    'TL': ['TL1','TL2','TL3','TL4','TL5','TL6','TL7','TL8','TL9'],\n",
    "    'SB': ['SB1','SB2','SB3','SB4'],\n",
    "    'NB': ['NB1','NB2','NB3','NB8','NB9'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_model(s):\n",
    "    \"\"\"Normalize to code like 'GR4' from text. Returns None if not parseable.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    m = re.search(r'\\b([A-Z]{2}\\d{1,2})\\b', str(s).upper())\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "def family(code):\n",
    "    return code[:2] if isinstance(code, str) and len(code) >= 2 else None\n",
    "\n",
    "def model_to_preferred_value(df_counts):\n",
    "    ref = df_counts.copy()\n",
    "    ref[\"MODEL_ref\"] = ref[\"MODEL\"].map(clean_model)\n",
    "    mv = (\n",
    "        ref.groupby([\"MODEL_ref\",\"VALUE\"], dropna=False)[\"pixels\"]\n",
    "           .sum()\n",
    "           .reset_index()\n",
    "    )\n",
    "    idx = mv.groupby(\"MODEL_ref\")[\"pixels\"].idxmax()\n",
    "    best = mv.loc[idx, [\"MODEL_ref\",\"VALUE\"]].dropna()\n",
    "    return dict(zip(best[\"MODEL_ref\"], best[\"VALUE\"]))\n",
    "\n",
    "def build_allowed_by_family(df_counts):\n",
    "    \"\"\"\n",
    "    From big-area df_counts, find which models are present (>0 pixels) per family.\n",
    "    Return ordered lists consistent with FAMILY_ORDERS.\n",
    "    \"\"\"\n",
    "    ref = df_counts.copy()\n",
    "    ref[\"MODEL_ref\"] = ref[\"MODEL\"].map(clean_model)\n",
    "    model_pixels = ref.groupby(\"MODEL_ref\", dropna=False)[\"pixels\"].sum()\n",
    "\n",
    "    present = {fam: set() for fam in FAMILY_ORDERS.keys()}\n",
    "    for m, pix in model_pixels.items():\n",
    "        if not isinstance(m, str) or pix <= 0:\n",
    "            continue\n",
    "        fam = family(m)\n",
    "        if fam in FAMILY_ORDERS:\n",
    "            present[fam].add(m)\n",
    "\n",
    "    allowed_by_family = {\n",
    "        fam: [x for x in FAMILY_ORDERS[fam] if x in present[fam]]\n",
    "        for fam in FAMILY_ORDERS.keys()\n",
    "    }\n",
    "    return allowed_by_family\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ring_type_modal(df_counts_ring, lut_df, fbfm40_meta):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with the dominant (modal) MODEL per general_type in the ring:\n",
    "      columns: general_type | MODEL_modal\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ring = df_counts_ring.copy()\n",
    "    ring = ring[['VALUE','pixels']].dropna()\n",
    "    ring['VALUE'] = pd.to_numeric(ring['VALUE'], errors='coerce').astype('Int64')\n",
    "\n",
    "    # VALUE -> MODEL, then attach general_type\n",
    "    ring = ring.merge(lut_df, on='VALUE', how='left').merge(fbfm40_meta, on='MODEL', how='left')\n",
    "\n",
    "    # Sum pixels per (general_type, MODEL), then take the modal MODEL per type\n",
    "    ring_tot = (ring.groupby(['general_type','MODEL'], dropna=False)['pixels']\n",
    "                    .sum().reset_index())\n",
    "    ring_tot = ring_tot.sort_values(['general_type','pixels'], ascending=[True, False])\n",
    "\n",
    "    ring_type_modal = (ring_tot.groupby('general_type', as_index=False)\n",
    "                              .first()[['general_type','MODEL']]\n",
    "                              .rename(columns={'MODEL':'MODEL_modal'}))\n",
    "    return ring_type_modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35a1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Apply ring modal mapping (type-constrained) to burned table ---\n",
    "def upgrade_to_ring_type_modal(df_counts_lf, df_counts_reference, ring_type_modal):\n",
    "    \"\"\"\n",
    "    Map each burned record to the ring's modal MODEL of the same general_type.\n",
    "    VALUE_after comes from the reference's canonical VALUE for that MODEL.\n",
    "    \"\"\"\n",
    "    out = df_counts_lf.copy()\n",
    "\n",
    "    # Ensure MODEL_before is clean code\n",
    "    out['MODEL_before'] = out['MODEL'].map(clean_model)\n",
    "    out = out.rename(columns={'VALUE':'VALUE_before'})\n",
    "\n",
    "    # Build canonical VALUE per MODEL from reference (unburned)\n",
    "    model_value_map = model_to_preferred_value(df_counts_reference)\n",
    "\n",
    "    # Join by general_type to get the ring's modal MODEL for that type\n",
    "    out = out.merge(ring_type_modal, on='general_type', how='left')\n",
    "\n",
    "    # If no modal found for that type (rare), keep original model\n",
    "    out['MODEL_after'] = out['MODEL_modal'].fillna(out['MODEL_before'])\n",
    "    out.drop(columns=['MODEL_modal'], inplace=True)\n",
    "\n",
    "    # VALUE_after via canonical mapping; fallback to VALUE_before if missing\n",
    "    out['VALUE_after'] = out['MODEL_after'].map(model_value_map).fillna(out['VALUE_before'])\n",
    "\n",
    "    # Optional neat column order\n",
    "    front = ['fid','MODEL_before','VALUE_before','MODEL_after','VALUE_after','general_type','climate','summary','pixels']\n",
    "    out = out[[c for c in front if c in out.columns] + [c for c in out.columns if c not in front]]\n",
    "\n",
    "    # Quick summaries if you want them:\n",
    "    before = out.groupby('MODEL_before', dropna=False)['pixels'].sum().sort_values(ascending=False)\n",
    "    after  = out.groupby('MODEL_after',  dropna=False)['pixels'].sum().sort_values(ascending=False)\n",
    "\n",
    "    return out, before.rename('pixels_before'), after.rename('pixels_after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d25f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build ring modal per general_type from your ring counts\n",
    "# df_counts_ring must have: VALUE, pixels  (counts from the ring buffer)\n",
    "ring_type_modal = build_ring_type_modal(df_counts_lf, lut_df, fbfm40_meta)\n",
    "\n",
    "# 2) Apply mapping to burned table, with VALUE_after from unburned reference\n",
    "upgraded_df_lf_ring, before, after = upgrade_to_ring_type_modal(\n",
    "    df_counts_lf,       # burned counts (inside)\n",
    "    df_counts,          # unburned reference (used only for canonical VALUEs)\n",
    "    ring_type_modal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af2959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ring_type_modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e190b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgraded_df_lf_ring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446d695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Grand totals must match\n",
    "tot_before = upgraded_df_lf[\"pixels\"].sum()\n",
    "tot_after  = upgraded_df_lf.groupby(\"MODEL_after\")[\"pixels\"].sum().sum()\n",
    "print(\"Grand totals equal?\", tot_before == tot_after, tot_before, tot_after)\n",
    "\n",
    "# 2) Family totals must match (we never cross families)\n",
    "bf_fam = (upgraded_df_lf.assign(fam=upgraded_df_lf[\"MODEL_before\"].str[:2])\n",
    "          .groupby(\"fam\")[\"pixels\"].sum().sort_values(ascending=False))\n",
    "af_fam = (upgraded_df_lf.assign(fam=upgraded_df_lf[\"MODEL_after\"].str[:2])\n",
    "          .groupby(\"fam\")[\"pixels\"].sum().sort_values(ascending=False))\n",
    "print(\"Family totals (before):\\n\", bf_fam)\n",
    "print(\"Family totals (after):\\n\",  af_fam)\n",
    "\n",
    "# 3) See exactly how pixels flowed from before -> after (confusion matrix)\n",
    "flow = (pd.crosstab(\n",
    "            upgraded_df_lf[\"MODEL_before\"],\n",
    "            upgraded_df_lf[\"MODEL_after\"],\n",
    "            values=upgraded_df_lf[\"pixels\"],\n",
    "            aggfunc=\"sum\",\n",
    "            dropna=False,\n",
    "        ).fillna(0).astype(int))\n",
    "print(flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cfd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "reclass_df = (\n",
    "    upgraded_df_lf[[\"VALUE_before\", \"VALUE_after\"]]\n",
    "      .dropna(subset=[\"VALUE_after\"])\n",
    "      .drop_duplicates()\n",
    "      .astype(int)\n",
    "      .sort_values([\"VALUE_before\", \"VALUE_after\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d45cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reclass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgraded_df_lf_simple = upgraded_df_lf.drop(columns=['fid', 'pixels', 'general_type', 'climate', 'summary','MODEL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433eca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgraded_df_lf_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapped_df = upgraded_df_lf_simple.drop(columns=['MODEL_before', 'VALUE_before'])\n",
    "remapped_df = remapped_df.rename(columns={'MODEL_after': 'MODEL', 'VALUE_after': 'VALUE'})\n",
    "remapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1195922",
   "metadata": {},
   "outputs": [],
   "source": [
    "fbfm40_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b43b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fbfm40_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eaf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapped_df = remapped_df.merge(fbfm40_meta, on=\"MODEL\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_lf_clean = remapped_df.rename(columns={'MODEL_after': 'MODEL', 'VALUE_after': 'VALUE'})\n",
    "\n",
    "df_counts_lf_clean[['general_type','MODEL', 'VALUE',  'climate', 'summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfaaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "remapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7e5e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_nearest_equal_or_higher(model, allowed_by_family, strict=False, upgrade_nb = False):\n",
    "#     \"\"\"\n",
    "#     If strict=False (default): map to nearest equal-or-higher rung present in reference.\n",
    "#     If strict=True:            map to nearest strictly-higher rung if available; else keep current.\n",
    "#     NBx models are unchanged.\n",
    "#     \"\"\"\n",
    "#     m = clean_model(model)\n",
    "#     if m is None:\n",
    "#         return model\n",
    "#     fam = family(m)\n",
    "#     if fam not in FAMILY_ORDERS:\n",
    "#         return m\n",
    "#     if fam == \"NB\" and not upgrade_nb:\n",
    "#         return m\n",
    "\n",
    "#     allowed = allowed_by_family.get(fam, [])\n",
    "#     if not allowed:\n",
    "#         return m\n",
    "\n",
    "#     try:\n",
    "#         idx_current = FAMILY_ORDERS[fam].index(m)\n",
    "#     except ValueError:\n",
    "#         # unknown rung -> fall back to family's max present\n",
    "#         return allowed[-1]\n",
    "\n",
    "#     for cand in allowed:\n",
    "#         idx_cand = FAMILY_ORDERS[fam].index(cand)\n",
    "#         if (idx_cand > idx_current) if strict else (idx_cand >= idx_current):\n",
    "#             return cand\n",
    "\n",
    "#     # No higher (strict) or equal/higher (non-strict) found\n",
    "#     return m if strict else allowed[-1]\n",
    "\n",
    "# def upgrade_latest_fire_nearest(df_counts, df_counts_lf, strict=False, upgrade_nb= False):\n",
    "#     \"\"\"\n",
    "#     Perform nearest_equal_or_higher upgrades using df_counts (reference) and\n",
    "#     apply to df_counts_lf (latest fire).\n",
    "#     Returns: (upgraded_df_lf, before_pixels, after_pixels, mapping_df)\n",
    "#     \"\"\"\n",
    "#     allowed_by_family = build_allowed_by_family(df_counts)\n",
    "#     model_value_map = model_to_preferred_value(df_counts)\n",
    "\n",
    "#     out = df_counts_lf.copy()\n",
    "#      # BEFORE / AFTER columns\n",
    "#     out[\"MODEL_before\"] = out[\"MODEL\"].map(clean_model)         # normalized but human-readable\n",
    "#     out[\"MODEL_after\"]  = out[\"MODEL_before\"].apply(lambda m: map_nearest_equal_or_higher(m, allowed_by_family, strict=strict, upgrade_nb=upgrade_nb))\n",
    "#     out = out.rename(columns={\"VALUE\": \"VALUE_before\"})           # keep original numeric code\n",
    "#     out[\"VALUE_after\"]  = out[\"MODEL_after\"].map(model_value_map) #  numeric code in reference\n",
    "\n",
    "#     # Summaries (pixels by model)\n",
    "#     before = (\n",
    "#         out.groupby(\"MODEL_before\", dropna=False)[\"pixels\"]\n",
    "#            .sum().sort_values(ascending=False)\n",
    "#            .rename(\"pixels_before\")\n",
    "#     )\n",
    "#     after = (\n",
    "#         out.groupby(\"MODEL_after\", dropna=False)[\"pixels\"]\n",
    "#            .sum().sort_values(ascending=False)\n",
    "#            .rename(\"pixels_after\")\n",
    "#     )\n",
    "\n",
    "#     # Mapping table (distinct models seen in latest fire)\n",
    "#     mapping = (\n",
    "#         out[[\"MODEL_before\",\"MODEL_after\"]]\n",
    "#           .drop_duplicates()\n",
    "#           .sort_values([\"MODEL_before\",\"MODEL_after\"])\n",
    "#           .reset_index(drop=True)\n",
    "#     )\n",
    "#     mapping[\"VALUE_pref_ref_before\"] = mapping[\"MODEL_before\"].map(model_value_map)\n",
    "#     mapping[\"VALUE_pref_ref_after\"]  = mapping[\"MODEL_after\"].map(model_value_map)\n",
    "\n",
    "#     # Reorder key columns up front (nice to view)\n",
    "#     front = [\"fid\",\"MODEL_before\",\"VALUE_before\",\"MODEL_after\",\"VALUE_after\",\"pixels\"]\n",
    "#     cols = [c for c in front if c in out.columns] + [c for c in out.columns if c not in front]\n",
    "#     out = out[cols]\n",
    "\n",
    "#     return out, before, after, mapping\n",
    "# upgraded_df_lf, before, after, mapping = upgrade_latest_fire_nearest(\n",
    "#     df_counts=df_counts,\n",
    "#     df_counts_lf=df_counts_lf,\n",
    "#     strict=True,\n",
    "#     upgrade_nb= False\n",
    "# )\n",
    "# print(mapping)\n",
    "# print(before.head(10))\n",
    "# print(after.head(10))\n",
    "# upgraded_df_lf.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
